## Next Point-of-Interest Recommendation on Resource-Constrained Moble Devices

The paper proposes to recommend next poi by mobile devices and designs a light weight model (LLREC) as recommender system. The author utilizes **FastGRNN** as its main building network and compress the model size by adopting **tensor-train decomposition** due to the limited computing resource and memory space of mobile devices. Besides, an innovative **teacher-student training framework** is employed to enhance the model performance.

Specifically, the **teacher** model is trained on rich data, which could model the users' short-term preference and long-term preference using **recent check-ins** and **user history check-ins**, respectively. It menas that there are two inputs for **teacher** model. But the **student** model, i.e., LLREC, purely regards the recent check-ins as input. Note that check-ins used in **teacher** model contain additional **contextual information** such as POI category than **student** model. 

Therefore, we will first train the **teacher** model by 
check-ins with contextual information in the form of **one positive sample and one hundred negative samples**. Then, given some candidate POIs, the well-trained **teacher** model will generate **a list of scores**. Next, we select the **top-K** and **bottom-K** recommendations as **additional** positive and negetive samples for **student** model from the score list. 

The recent check-ins will be converted into embedding vectors by a POI embedding matirx **originally** in **student** model, but the author proposes to compact the matirx by **tensor-train decomposition** due to the limited memory space of mobile devices. Then the generated embedding vectors are fed into **FastGRNN** that considers spatiotemporal correlation between two adjacent check-ins using **time-specific** matrix and **distance-specific** matirx to get all hidden states.
Finally, the **last hidden state** is used to compute the scores of one positive sample and one hundred negative samples. The **Bayesian personalized ranking(BPR)** pair-wise loss function is chosen to calculate the loss between "positive" and "negative" scores. Moreover, the **addtional** K positive and negative samples transfered by **teacher** model will also be used to compute scores with the **last hidden state**. Hence, we choose **KD** loss function to calculate the loss between "positive" and "negative" scores. The sum of two losses is regarded as total loss in **student** model.

It is worth noting that the process of modeling **short-term** preference in the **teacher** model is similar to that in the **student** model. And an **attention-based** method is used to model **long-term** preference in **teacher** model.